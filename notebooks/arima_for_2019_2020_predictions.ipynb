{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QvOBjZ03gC53"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize']=10,6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "9CvyC6UWgO3M",
        "outputId": "c699527b-43e8-4755-81f9-1a38ab2799c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>demand_point_index</th>\n",
              "      <th>x_coordinate</th>\n",
              "      <th>y_coordinate</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.352242</td>\n",
              "      <td>0.667932</td>\n",
              "      <td>0.958593</td>\n",
              "      <td>2.911901</td>\n",
              "      <td>4.338274</td>\n",
              "      <td>6.561995</td>\n",
              "      <td>8.454417</td>\n",
              "      <td>10.595324</td>\n",
              "      <td>13.119572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.325940</td>\n",
              "      <td>0.591964</td>\n",
              "      <td>0.862652</td>\n",
              "      <td>2.589068</td>\n",
              "      <td>4.196034</td>\n",
              "      <td>5.745551</td>\n",
              "      <td>8.753195</td>\n",
              "      <td>11.126995</td>\n",
              "      <td>12.020091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.373752</td>\n",
              "      <td>0.591890</td>\n",
              "      <td>0.969733</td>\n",
              "      <td>2.641432</td>\n",
              "      <td>3.541772</td>\n",
              "      <td>5.469161</td>\n",
              "      <td>8.414627</td>\n",
              "      <td>10.115336</td>\n",
              "      <td>14.018254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.420686</td>\n",
              "      <td>0.584055</td>\n",
              "      <td>0.906547</td>\n",
              "      <td>2.378577</td>\n",
              "      <td>3.888121</td>\n",
              "      <td>5.846089</td>\n",
              "      <td>9.083868</td>\n",
              "      <td>12.424885</td>\n",
              "      <td>15.012302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.475621</td>\n",
              "      <td>0.647940</td>\n",
              "      <td>0.981544</td>\n",
              "      <td>2.665400</td>\n",
              "      <td>4.218711</td>\n",
              "      <td>6.776609</td>\n",
              "      <td>8.851107</td>\n",
              "      <td>11.731131</td>\n",
              "      <td>16.355563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>4091</td>\n",
              "      <td>59.5</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0.171015</td>\n",
              "      <td>0.334565</td>\n",
              "      <td>0.556055</td>\n",
              "      <td>1.373291</td>\n",
              "      <td>1.837586</td>\n",
              "      <td>2.517146</td>\n",
              "      <td>3.352280</td>\n",
              "      <td>4.149888</td>\n",
              "      <td>5.426193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>4092</td>\n",
              "      <td>60.5</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0.041716</td>\n",
              "      <td>0.061741</td>\n",
              "      <td>0.131291</td>\n",
              "      <td>0.386540</td>\n",
              "      <td>0.755846</td>\n",
              "      <td>0.941116</td>\n",
              "      <td>1.107797</td>\n",
              "      <td>1.309479</td>\n",
              "      <td>2.057450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>4093</td>\n",
              "      <td>61.5</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0.100895</td>\n",
              "      <td>0.180352</td>\n",
              "      <td>0.296299</td>\n",
              "      <td>0.705373</td>\n",
              "      <td>1.300220</td>\n",
              "      <td>1.608609</td>\n",
              "      <td>1.822806</td>\n",
              "      <td>2.333681</td>\n",
              "      <td>3.218519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>4094</td>\n",
              "      <td>62.5</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0.155353</td>\n",
              "      <td>0.290825</td>\n",
              "      <td>0.557803</td>\n",
              "      <td>1.516066</td>\n",
              "      <td>2.399426</td>\n",
              "      <td>2.719197</td>\n",
              "      <td>4.494515</td>\n",
              "      <td>6.096858</td>\n",
              "      <td>6.262574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>4095</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0.209372</td>\n",
              "      <td>0.340185</td>\n",
              "      <td>0.749491</td>\n",
              "      <td>1.904285</td>\n",
              "      <td>2.775772</td>\n",
              "      <td>3.404641</td>\n",
              "      <td>4.574922</td>\n",
              "      <td>6.301078</td>\n",
              "      <td>6.860939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      demand_point_index  x_coordinate  y_coordinate      2010      2011  \\\n",
              "0                      0           0.5           0.5  0.352242  0.667932   \n",
              "1                      1           1.5           0.5  0.325940  0.591964   \n",
              "2                      2           2.5           0.5  0.373752  0.591890   \n",
              "3                      3           3.5           0.5  0.420686  0.584055   \n",
              "4                      4           4.5           0.5  0.475621  0.647940   \n",
              "...                  ...           ...           ...       ...       ...   \n",
              "4091                4091          59.5          63.5  0.171015  0.334565   \n",
              "4092                4092          60.5          63.5  0.041716  0.061741   \n",
              "4093                4093          61.5          63.5  0.100895  0.180352   \n",
              "4094                4094          62.5          63.5  0.155353  0.290825   \n",
              "4095                4095          63.5          63.5  0.209372  0.340185   \n",
              "\n",
              "          2012      2013      2014      2015      2016       2017       2018  \n",
              "0     0.958593  2.911901  4.338274  6.561995  8.454417  10.595324  13.119572  \n",
              "1     0.862652  2.589068  4.196034  5.745551  8.753195  11.126995  12.020091  \n",
              "2     0.969733  2.641432  3.541772  5.469161  8.414627  10.115336  14.018254  \n",
              "3     0.906547  2.378577  3.888121  5.846089  9.083868  12.424885  15.012302  \n",
              "4     0.981544  2.665400  4.218711  6.776609  8.851107  11.731131  16.355563  \n",
              "...        ...       ...       ...       ...       ...        ...        ...  \n",
              "4091  0.556055  1.373291  1.837586  2.517146  3.352280   4.149888   5.426193  \n",
              "4092  0.131291  0.386540  0.755846  0.941116  1.107797   1.309479   2.057450  \n",
              "4093  0.296299  0.705373  1.300220  1.608609  1.822806   2.333681   3.218519  \n",
              "4094  0.557803  1.516066  2.399426  2.719197  4.494515   6.096858   6.262574  \n",
              "4095  0.749491  1.904285  2.775772  3.404641  4.574922   6.301078   6.860939  \n",
              "\n",
              "[4096 rows x 12 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv('D:/shell hackathon 2022 github/Shell_Datathon_2022/data/Demand_History.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "Ligdb9gKgprL",
        "outputId": "81c1790d-b367-4884-ff64-2347caa3c2be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>4086</th>\n",
              "      <th>4087</th>\n",
              "      <th>4088</th>\n",
              "      <th>4089</th>\n",
              "      <th>4090</th>\n",
              "      <th>4091</th>\n",
              "      <th>4092</th>\n",
              "      <th>4093</th>\n",
              "      <th>4094</th>\n",
              "      <th>4095</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-01</th>\n",
              "      <td>0.352242</td>\n",
              "      <td>0.325940</td>\n",
              "      <td>0.373752</td>\n",
              "      <td>0.420686</td>\n",
              "      <td>0.475621</td>\n",
              "      <td>0.380156</td>\n",
              "      <td>0.449348</td>\n",
              "      <td>0.470071</td>\n",
              "      <td>0.537307</td>\n",
              "      <td>0.445734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114351</td>\n",
              "      <td>0.075160</td>\n",
              "      <td>0.081059</td>\n",
              "      <td>0.083821</td>\n",
              "      <td>0.158356</td>\n",
              "      <td>0.171015</td>\n",
              "      <td>0.041716</td>\n",
              "      <td>0.100895</td>\n",
              "      <td>0.155353</td>\n",
              "      <td>0.209372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-01</th>\n",
              "      <td>0.667932</td>\n",
              "      <td>0.591964</td>\n",
              "      <td>0.591890</td>\n",
              "      <td>0.584055</td>\n",
              "      <td>0.647940</td>\n",
              "      <td>0.725189</td>\n",
              "      <td>0.730466</td>\n",
              "      <td>0.866474</td>\n",
              "      <td>0.833661</td>\n",
              "      <td>0.775279</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185420</td>\n",
              "      <td>0.131877</td>\n",
              "      <td>0.138802</td>\n",
              "      <td>0.158354</td>\n",
              "      <td>0.376271</td>\n",
              "      <td>0.334565</td>\n",
              "      <td>0.061741</td>\n",
              "      <td>0.180352</td>\n",
              "      <td>0.290825</td>\n",
              "      <td>0.340185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-01</th>\n",
              "      <td>0.958593</td>\n",
              "      <td>0.862652</td>\n",
              "      <td>0.969733</td>\n",
              "      <td>0.906547</td>\n",
              "      <td>0.981544</td>\n",
              "      <td>1.076054</td>\n",
              "      <td>1.220484</td>\n",
              "      <td>1.615454</td>\n",
              "      <td>1.622691</td>\n",
              "      <td>1.316209</td>\n",
              "      <td>...</td>\n",
              "      <td>0.489806</td>\n",
              "      <td>0.298811</td>\n",
              "      <td>0.227962</td>\n",
              "      <td>0.393987</td>\n",
              "      <td>0.670141</td>\n",
              "      <td>0.556055</td>\n",
              "      <td>0.131291</td>\n",
              "      <td>0.296299</td>\n",
              "      <td>0.557803</td>\n",
              "      <td>0.749491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>2.911901</td>\n",
              "      <td>2.589068</td>\n",
              "      <td>2.641432</td>\n",
              "      <td>2.378577</td>\n",
              "      <td>2.665400</td>\n",
              "      <td>2.762618</td>\n",
              "      <td>2.655187</td>\n",
              "      <td>3.273061</td>\n",
              "      <td>3.366533</td>\n",
              "      <td>3.795858</td>\n",
              "      <td>...</td>\n",
              "      <td>1.285151</td>\n",
              "      <td>0.819191</td>\n",
              "      <td>0.604009</td>\n",
              "      <td>0.966916</td>\n",
              "      <td>1.584710</td>\n",
              "      <td>1.373291</td>\n",
              "      <td>0.386540</td>\n",
              "      <td>0.705373</td>\n",
              "      <td>1.516066</td>\n",
              "      <td>1.904285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>4.338274</td>\n",
              "      <td>4.196034</td>\n",
              "      <td>3.541772</td>\n",
              "      <td>3.888121</td>\n",
              "      <td>4.218711</td>\n",
              "      <td>4.220747</td>\n",
              "      <td>5.333594</td>\n",
              "      <td>5.442867</td>\n",
              "      <td>5.973267</td>\n",
              "      <td>4.781361</td>\n",
              "      <td>...</td>\n",
              "      <td>2.168647</td>\n",
              "      <td>1.086649</td>\n",
              "      <td>1.012104</td>\n",
              "      <td>1.703340</td>\n",
              "      <td>2.272350</td>\n",
              "      <td>1.837586</td>\n",
              "      <td>0.755846</td>\n",
              "      <td>1.300220</td>\n",
              "      <td>2.399426</td>\n",
              "      <td>2.775772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>6.561995</td>\n",
              "      <td>5.745551</td>\n",
              "      <td>5.469161</td>\n",
              "      <td>5.846089</td>\n",
              "      <td>6.776609</td>\n",
              "      <td>6.760395</td>\n",
              "      <td>8.620496</td>\n",
              "      <td>8.681284</td>\n",
              "      <td>10.033183</td>\n",
              "      <td>9.277640</td>\n",
              "      <td>...</td>\n",
              "      <td>3.320948</td>\n",
              "      <td>1.427004</td>\n",
              "      <td>1.158568</td>\n",
              "      <td>2.083558</td>\n",
              "      <td>3.635703</td>\n",
              "      <td>2.517146</td>\n",
              "      <td>0.941116</td>\n",
              "      <td>1.608609</td>\n",
              "      <td>2.719197</td>\n",
              "      <td>3.404641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-01</th>\n",
              "      <td>8.454417</td>\n",
              "      <td>8.753195</td>\n",
              "      <td>8.414627</td>\n",
              "      <td>9.083868</td>\n",
              "      <td>8.851107</td>\n",
              "      <td>9.331196</td>\n",
              "      <td>11.406751</td>\n",
              "      <td>11.135352</td>\n",
              "      <td>13.210567</td>\n",
              "      <td>10.992479</td>\n",
              "      <td>...</td>\n",
              "      <td>4.336336</td>\n",
              "      <td>1.924844</td>\n",
              "      <td>1.350226</td>\n",
              "      <td>2.802044</td>\n",
              "      <td>5.880033</td>\n",
              "      <td>3.352280</td>\n",
              "      <td>1.107797</td>\n",
              "      <td>1.822806</td>\n",
              "      <td>4.494515</td>\n",
              "      <td>4.574922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10.595324</td>\n",
              "      <td>11.126995</td>\n",
              "      <td>10.115336</td>\n",
              "      <td>12.424885</td>\n",
              "      <td>11.731131</td>\n",
              "      <td>14.743943</td>\n",
              "      <td>13.115854</td>\n",
              "      <td>14.708272</td>\n",
              "      <td>17.291626</td>\n",
              "      <td>17.386210</td>\n",
              "      <td>...</td>\n",
              "      <td>6.095297</td>\n",
              "      <td>2.054926</td>\n",
              "      <td>1.598313</td>\n",
              "      <td>3.284002</td>\n",
              "      <td>7.672174</td>\n",
              "      <td>4.149888</td>\n",
              "      <td>1.309479</td>\n",
              "      <td>2.333681</td>\n",
              "      <td>6.096858</td>\n",
              "      <td>6.301078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01</th>\n",
              "      <td>13.119572</td>\n",
              "      <td>12.020091</td>\n",
              "      <td>14.018254</td>\n",
              "      <td>15.012302</td>\n",
              "      <td>16.355563</td>\n",
              "      <td>17.559998</td>\n",
              "      <td>19.696415</td>\n",
              "      <td>19.367417</td>\n",
              "      <td>21.899847</td>\n",
              "      <td>21.765241</td>\n",
              "      <td>...</td>\n",
              "      <td>6.625857</td>\n",
              "      <td>3.612612</td>\n",
              "      <td>2.643128</td>\n",
              "      <td>4.127373</td>\n",
              "      <td>7.833432</td>\n",
              "      <td>5.426193</td>\n",
              "      <td>2.057450</td>\n",
              "      <td>3.218519</td>\n",
              "      <td>6.262574</td>\n",
              "      <td>6.860939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows × 4096 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0          1          2          3          4          5     \\\n",
              "2010-01-01   0.352242   0.325940   0.373752   0.420686   0.475621   0.380156   \n",
              "2011-01-01   0.667932   0.591964   0.591890   0.584055   0.647940   0.725189   \n",
              "2012-01-01   0.958593   0.862652   0.969733   0.906547   0.981544   1.076054   \n",
              "2013-01-01   2.911901   2.589068   2.641432   2.378577   2.665400   2.762618   \n",
              "2014-01-01   4.338274   4.196034   3.541772   3.888121   4.218711   4.220747   \n",
              "2015-01-01   6.561995   5.745551   5.469161   5.846089   6.776609   6.760395   \n",
              "2016-01-01   8.454417   8.753195   8.414627   9.083868   8.851107   9.331196   \n",
              "2017-01-01  10.595324  11.126995  10.115336  12.424885  11.731131  14.743943   \n",
              "2018-01-01  13.119572  12.020091  14.018254  15.012302  16.355563  17.559998   \n",
              "\n",
              "                 6          7          8          9     ...      4086  \\\n",
              "2010-01-01   0.449348   0.470071   0.537307   0.445734  ...  0.114351   \n",
              "2011-01-01   0.730466   0.866474   0.833661   0.775279  ...  0.185420   \n",
              "2012-01-01   1.220484   1.615454   1.622691   1.316209  ...  0.489806   \n",
              "2013-01-01   2.655187   3.273061   3.366533   3.795858  ...  1.285151   \n",
              "2014-01-01   5.333594   5.442867   5.973267   4.781361  ...  2.168647   \n",
              "2015-01-01   8.620496   8.681284  10.033183   9.277640  ...  3.320948   \n",
              "2016-01-01  11.406751  11.135352  13.210567  10.992479  ...  4.336336   \n",
              "2017-01-01  13.115854  14.708272  17.291626  17.386210  ...  6.095297   \n",
              "2018-01-01  19.696415  19.367417  21.899847  21.765241  ...  6.625857   \n",
              "\n",
              "                4087      4088      4089      4090      4091      4092  \\\n",
              "2010-01-01  0.075160  0.081059  0.083821  0.158356  0.171015  0.041716   \n",
              "2011-01-01  0.131877  0.138802  0.158354  0.376271  0.334565  0.061741   \n",
              "2012-01-01  0.298811  0.227962  0.393987  0.670141  0.556055  0.131291   \n",
              "2013-01-01  0.819191  0.604009  0.966916  1.584710  1.373291  0.386540   \n",
              "2014-01-01  1.086649  1.012104  1.703340  2.272350  1.837586  0.755846   \n",
              "2015-01-01  1.427004  1.158568  2.083558  3.635703  2.517146  0.941116   \n",
              "2016-01-01  1.924844  1.350226  2.802044  5.880033  3.352280  1.107797   \n",
              "2017-01-01  2.054926  1.598313  3.284002  7.672174  4.149888  1.309479   \n",
              "2018-01-01  3.612612  2.643128  4.127373  7.833432  5.426193  2.057450   \n",
              "\n",
              "                4093      4094      4095  \n",
              "2010-01-01  0.100895  0.155353  0.209372  \n",
              "2011-01-01  0.180352  0.290825  0.340185  \n",
              "2012-01-01  0.296299  0.557803  0.749491  \n",
              "2013-01-01  0.705373  1.516066  1.904285  \n",
              "2014-01-01  1.300220  2.399426  2.775772  \n",
              "2015-01-01  1.608609  2.719197  3.404641  \n",
              "2016-01-01  1.822806  4.494515  4.574922  \n",
              "2017-01-01  2.333681  6.096858  6.301078  \n",
              "2018-01-01  3.218519  6.262574  6.860939  \n",
              "\n",
              "[9 rows x 4096 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pandas.core.indexes.interval import date_range\n",
        "ndf=df.T.iloc[3:,:]\n",
        "ndf.index=pd.to_datetime(ndf.index)\n",
        "ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARIMA model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tvEihnoY0-eK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "d:\\shell hackathon 2022 github\\Shell_Datathon_2022\\shell\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ],
      "source": [
        "pred_2019=[]\n",
        "pred_2020=[]\n",
        "# from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "for i in range(4096):\n",
        "  dataset=ndf.iloc[:,i]\n",
        "  dataset=np.asanyarray(dataset)\n",
        "  #dataset=pd.DataFrame([1.849883,4.017967,7.552549,19.323394,31.891712,42.249471,58.718724,75.805574,88.264071])\n",
        "  #dataset.index=pd.to_datetime(ndf.index)\n",
        "  model = ARIMA(dataset,order=(0,2,1))\n",
        "  results_ARIMA = model.fit(start_params=(0,1))\n",
        "  # Forecast for 2 steps ahead\n",
        "  forecast_values = results_ARIMA.forecast(steps=2)\n",
        "  # Append values to the prediction lists\n",
        "  pred_2019.append(forecast_values[0])\n",
        "  pred_2020.append(forecast_values[1])\n",
        "  # pred_2019.append(results_ARIMA.forecast(2)[0][0])\n",
        "  # pred_2020.append(results_ARIMA.forecast(2)[0][1])\n",
        "  # plt.plot(dataset)\n",
        "  # plt.plot(results_ARIMA.fittedvalues ,color='red')\n",
        "  # plt.title('RSS:%.4f'%sum((results_ARIMA.fittedvalues-dataset[1])**2))\n",
        "  # print('plotting AR model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storing the predictions in DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OT8iIH9YcIdI",
        "outputId": "18113ca9-b616-436e-8ca3-8dfbc6f81640"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_2019</th>\n",
              "      <th>pred_2020</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.539544</td>\n",
              "      <td>17.959517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.160288</td>\n",
              "      <td>14.300485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17.232578</td>\n",
              "      <td>20.446903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.185220</td>\n",
              "      <td>19.358138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.079744</td>\n",
              "      <td>25.803925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>6.572086</td>\n",
              "      <td>7.717979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>2.936648</td>\n",
              "      <td>3.815846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>4.293351</td>\n",
              "      <td>5.368183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>7.079237</td>\n",
              "      <td>7.895901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>7.819941</td>\n",
              "      <td>8.778943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pred_2019  pred_2020\n",
              "0     15.539544  17.959517\n",
              "1     13.160288  14.300485\n",
              "2     17.232578  20.446903\n",
              "3     17.185220  19.358138\n",
              "4     21.079744  25.803925\n",
              "...         ...        ...\n",
              "4091   6.572086   7.717979\n",
              "4092   2.936648   3.815846\n",
              "4093   4.293351   5.368183\n",
              "4094   7.079237   7.895901\n",
              "4095   7.819941   8.778943\n",
              "\n",
              "[4096 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf=pd.DataFrame(pred_2019,columns=['pred_2019'])\n",
        "gdf['pred_2020']=pred_2020\n",
        "gdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting negative values to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DPZNBaQ2fE72"
      },
      "outputs": [],
      "source": [
        "for i in range(4096):\n",
        "  if pred_2019[i]<0:\n",
        "    pred_2019[i]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xshjh14EfQL1"
      },
      "outputs": [],
      "source": [
        "for i in range(4096):\n",
        "  if pred_2020[i]<0:\n",
        "    pred_2020[i]=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DY8DSgKteVaR"
      },
      "outputs": [],
      "source": [
        "gdf.to_csv('D:/shell hackathon 2022 github/Shell_Datathon_2022/predictions/arima_pred_latest.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XulnPb2JKM0R"
      },
      "outputs": [],
      "source": [
        "for i in range(4096):\n",
        "  if gdf['pred_2020'][i]<0:\n",
        "    print('0')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
